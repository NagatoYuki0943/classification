è®ºæ–‡åç§°ï¼š**RepVGG: Making VGG-style ConvNets Great Again**

è®ºæ–‡ä¸‹è½½åœ°å€ï¼šhttps://arxiv.org/abs/2101.03697

å®˜æ–¹æºç ï¼ˆPytorchå®ç°ï¼‰ï¼šhttps://github.com/DingXiaoH/RepVGG

------

https://blog.csdn.net/qq_37541097/article/details/125692507

https://mp.weixin.qq.com/s/c7o8xK0mSqF9aKK3w_7EIQ

ç›®å½•

- 0 å‰è¨€

- 1 RepVGG Blockè¯¦è§£

- 2 ç»“æ„é‡å‚æ•°åŒ–

- - 2.1 èåˆConv2då’ŒBN
    - 2.2 Conv2d+BNèåˆå®éªŒ(Pytorch)
    - 2.3 å°†1x1å·ç§¯è½¬æ¢æˆ3x3å·ç§¯
    - 2.4 å°†BNè½¬æ¢æˆ3x3å·ç§¯
    - 2.5 å¤šåˆ†æ”¯èåˆ
    - 2.6 ç»“æ„é‡å‚æ•°åŒ–å®éªŒ(Pytorch)

- 3 æ¨¡å‹é…ç½®

## 0 å‰è¨€

VGGç½‘ç»œæ˜¯2014å¹´ç”±ç‰›æ´¥å¤§å­¦è‘—åç ”ç©¶ç»„VGG (Visual Geometry Group)  æå‡ºçš„ã€‚åœ¨2014åˆ°2016å¹´ï¼ˆResNetæå‡ºä¹‹å‰ï¼‰ï¼ŒVGGç½‘ç»œå¯ä»¥è¯´æ˜¯å½“æ—¶æœ€ç«å¹¶è¢«å¹¿æ³›åº”ç”¨çš„Backboneã€‚åé¢ç”±äºå„ç§æ–°çš„ç½‘ç»œæå‡ºï¼Œè®ºç²¾åº¦VGGæ¯”ä¸ä¸ŠResNetï¼Œè®ºé€Ÿåº¦å’Œå‚æ•°æ•°é‡VGGæ¯”ä¸è¿‡MobileNetç­‰è½»é‡çº§ç½‘ç»œï¼Œæ…¢æ…¢åœ°VGGå¼€å§‹æ·¡å‡ºäººä»¬çš„è§†çº¿ã€‚å½“VGGå·²ç»è¢«å¤§å®¶é—å¿˜æ—¶ï¼Œ2021å¹´æ¸…åå¤§å­¦ã€æ—·è§†ç§‘æŠ€ä»¥åŠé¦™æ¸¯ç§‘æŠ€å¤§å­¦ç­‰æœºæ„å…±åŒæå‡ºäº†RepVGGç½‘ç»œï¼Œå¸Œæœ›èƒ½å¤Ÿè®©VGG-styleç½‘ç»œGreat Againã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](2101.03697 RepVGG.assets/RepVGGæ€§èƒ½.png)

é€šè¿‡è®ºæ–‡çš„å›¾ä¸€å¯ä»¥çœ‹å‡ºï¼ŒRepVGGæ— è®ºæ˜¯åœ¨ç²¾åº¦è¿˜æ˜¯é€Ÿåº¦ä¸Šéƒ½å·²ç»è¶…è¿‡äº†ResNetã€EffcientNetä»¥åŠReNeXtç­‰ç½‘ç»œã€‚é‚£RepVGGç©¶ç«Ÿç”¨äº†ä»€ä¹ˆæ–¹æ³•ä½¿å¾—VGGç½‘ç»œèƒ½å¤Ÿè·å¾—å¦‚æ­¤å¤§çš„æå‡å‘¢ï¼Œåœ¨è®ºæ–‡çš„æ‘˜è¦ä¸­ï¼Œä½œè€…æåˆ°äº†`structural re-parameterization technique`æ–¹æ³•ï¼Œå³**ç»“æ„é‡å‚æ•°åŒ–**ã€‚å®é™…ä¸Šå°±æ˜¯åœ¨è®­ç»ƒæ—¶ï¼Œä½¿ç”¨ä¸€ä¸ªç±»ä¼¼ResNet-styleçš„å¤šåˆ†æ”¯æ¨¡å‹ï¼Œè€Œæ¨ç†æ—¶è½¬åŒ–æˆVGG-styleçš„å•è·¯æ¨¡å‹ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå›¾ï¼ˆBï¼‰è¡¨ç¤ºRepVGGè®­ç»ƒæ—¶æ‰€é‡‡ç”¨çš„ç½‘ç»œç»“æ„ï¼Œè€Œåœ¨æ¨ç†æ—¶é‡‡ç”¨å›¾ï¼ˆCï¼‰çš„ç½‘ç»œç»“æ„ã€‚å…³äºå¦‚ä½•å°†å›¾ï¼ˆBï¼‰è½¬æ¢åˆ°å›¾ï¼ˆCï¼‰ä»¥åŠä¸ºä»€ä¹ˆè¦è¿™ä¹ˆåšåé¢å†ç»†è¯´ï¼Œå¦‚æœå¯¹æ¨¡å‹ä¼˜åŒ–éƒ¨ç½²æœ‰äº†è§£å°±ä¼šå‘ç°è¿™å’Œåšç½‘ç»œå›¾ä¼˜åŒ–æˆ–è€…è¯´ç®—å­èåˆéå¸¸ç±»ä¼¼ã€‚

![](2101.03697 RepVGG.assets/ç»“æ„é‡å‚æ•°åŒ–.png)

## 1 RepVGG Blockè¯¦è§£

å…¶å®å…³äºRepVGGæ•´ä¸ªæ¨¡å‹æ²¡å¤ªå¤šå¥½è¯´çš„ï¼Œå°±æ˜¯åœ¨ä¸æ–­å †å RepVGG Blockï¼Œåªè¦ä¹‹å‰çœ‹è¿‡VGGä»¥åŠResNetçš„ä»£ç ï¼Œé‚£ä¹ˆRepVGGä¹Ÿä¸åœ¨è¯ä¸‹ã€‚è¿™é‡Œä¸»è¦è¿˜æ˜¯èŠä¸‹RepVGG  Blockä¸­çš„ä¸€äº›ç»†èŠ‚ã€‚ç”±äºè®ºæ–‡ä¸­çš„å›¾éƒ½æ˜¯ç®€åŒ–è¿‡çš„ï¼Œäºæ˜¯æˆ‘è‡ªå·±æ ¹æ®æºç ç»˜åˆ¶äº†ä¸‹å›¾çš„RepVGG  Blockï¼ˆæ³¨æ„æ˜¯é’ˆå¯¹è®­ç»ƒæ—¶é‡‡ç”¨çš„ç»“æ„ï¼‰ã€‚

å›¾ï¼ˆaï¼‰æ˜¯è¿›è¡Œä¸‹é‡‡æ ·ï¼ˆstride=2ï¼‰æ—¶ä½¿ç”¨çš„RepVGG  Blockç»“æ„ï¼Œ

å›¾ï¼ˆbï¼‰æ˜¯æ­£å¸¸çš„ï¼ˆstride=1ï¼‰RepVGG Blockç»“æ„ã€‚é€šè¿‡å›¾ï¼ˆbï¼‰å¯ä»¥çœ‹åˆ°è®­ç»ƒæ—¶RepVGG  Blockå¹¶è¡Œäº†ä¸‰ä¸ªåˆ†æ”¯ï¼šä¸€ä¸ªå·ç§¯æ ¸å¤§å°ä¸º`3x3`çš„ä¸»åˆ†æ”¯ï¼Œä¸€ä¸ªå·ç§¯æ ¸å¤§å°ä¸º`1x1`çš„shortcutåˆ†æ”¯ä»¥åŠä¸€ä¸ªåªè¿äº†BNçš„shortcutåˆ†æ”¯ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](2101.03697 RepVGG.assets/RepVGG Block.png)

è¿™é‡Œé¦–å…ˆæŠ›å‡ºä¸€ä¸ªé—®é¢˜ï¼Œ**ä¸ºä»€ä¹ˆè®­ç»ƒæ—¶è¦é‡‡ç”¨å¤šåˆ†æ”¯ç»“æ„**ã€‚å¦‚æœä¹‹å‰çœ‹è¿‡åƒInceptionç³»åˆ—ã€ResNetä»¥åŠDenseNetç­‰æ¨¡å‹ï¼Œæˆ‘ä»¬èƒ½å¤Ÿå‘ç°è¿™äº›æ¨¡å‹éƒ½å¹¶è¡Œäº†å¤šä¸ªåˆ†æ”¯ã€‚è‡³å°‘æ ¹æ®ç°æœ‰çš„ä¸€äº›ç»éªŒæ¥çœ‹ï¼Œå¹¶è¡Œå¤šä¸ªåˆ†æ”¯ä¸€èˆ¬èƒ½å¤Ÿå¢åŠ æ¨¡å‹çš„è¡¨å¾èƒ½åŠ›ã€‚æ‰€ä»¥ä½ ä¼šå‘ç°ä¸€äº›è®ºæ–‡å–œæ¬¢å„ç§é­”æ”¹ç½‘ç»œå¹¶è¡Œåˆ†æ”¯ã€‚åœ¨è®ºæ–‡çš„è¡¨6ä¸­ï¼Œä½œè€…ä¹Ÿåšäº†ä¸ªç®€å•çš„æ¶ˆèå®éªŒï¼Œåœ¨ä½¿ç”¨å•è·¯ç»“æ„æ—¶ï¼ˆä¸ä½¿ç”¨å…¶ä»–ä»»ä½•åˆ†æ”¯ï¼‰Accå¤§æ¦‚ä¸º`72.39`ï¼Œåœ¨åŠ ä¸Š`Identity branch`ä»¥åŠ`1x1 branch`åAccè¾¾åˆ°äº†`75.14`ã€‚

![](2101.03697 RepVGG.assets/è®­ç»ƒæ—¶é‡‡ç”¨å¤šåˆ†æ”¯ç»“æ„å¥½å¤„.png)

æ¥ç€å†é—®å¦å¤–ä¸€ä¸ªé—®é¢˜ï¼Œ**ä¸ºä»€ä¹ˆæ¨ç†æ—¶ä½œè€…è¦å°†å¤šåˆ†æ”¯æ¨¡å‹è½¬æ¢æˆå•è·¯æ¨¡å‹**ã€‚æ ¹æ®è®ºæ–‡`3.1`ç« èŠ‚çš„å†…å®¹å¯çŸ¥ï¼Œé‡‡ç”¨å•è·¯æ¨¡å‹ä¼šæ›´å¿«ã€æ›´çœå†…å­˜å¹¶ä¸”æ›´åŠ çš„çµæ´»ã€‚

- **æ›´å¿«**ï¼šä¸»è¦æ˜¯è€ƒè™‘åˆ°æ¨¡å‹åœ¨æ¨ç†æ—¶ç¡¬ä»¶è®¡ç®—çš„å¹¶è¡Œç¨‹åº¦ä»¥åŠMACï¼ˆmemory access  costï¼‰ï¼Œå¯¹äºå¤šåˆ†æ”¯æ¨¡å‹ï¼Œç¡¬ä»¶éœ€è¦åˆ†åˆ«è®¡ç®—æ¯ä¸ªåˆ†æ”¯çš„ç»“æœï¼Œæœ‰çš„åˆ†æ”¯è®¡ç®—çš„å¿«ï¼Œæœ‰çš„åˆ†æ”¯è®¡ç®—çš„æ…¢ï¼Œè€Œè®¡ç®—å¿«çš„åˆ†æ”¯è®¡ç®—å®Œååªèƒ½å¹²ç­‰ç€ï¼Œç­‰å…¶ä»–åˆ†æ”¯éƒ½è®¡ç®—å®Œåæ‰èƒ½åšè¿›ä¸€æ­¥èåˆï¼Œè¿™æ ·ä¼šå¯¼è‡´ç¡¬ä»¶ç®—åŠ›ä¸èƒ½å……åˆ†åˆ©ç”¨ï¼Œæˆ–è€…è¯´å¹¶è¡Œåº¦ä¸å¤Ÿé«˜ã€‚è€Œä¸”æ¯ä¸ªåˆ†æ”¯éƒ½éœ€è¦å»è®¿é—®ä¸€æ¬¡å†…å­˜ï¼Œè®¡ç®—å®Œåè¿˜éœ€è¦å°†è®¡ç®—ç»“æœå­˜å…¥å†…å­˜ï¼ˆä¸æ–­åœ°è®¿é—®å’Œå†™å…¥å†…å­˜ä¼šåœ¨IOä¸Šæµªè´¹å¾ˆå¤šæ—¶é—´ï¼‰ã€‚

- **æ›´çœå†…å­˜**ï¼šåœ¨è®ºæ–‡çš„å›¾3å½“ä¸­ï¼Œä½œè€…ä¸¾äº†ä¸ªä¾‹å­ï¼Œå¦‚å›¾ï¼ˆAï¼‰æ‰€ç¤ºçš„Residualæ¨¡å—ï¼Œå‡è®¾å·ç§¯å±‚ä¸æ”¹å˜channelçš„æ•°é‡ï¼Œé‚£ä¹ˆåœ¨ä¸»åˆ†æ”¯å’Œshortcutåˆ†æ”¯ä¸Šéƒ½è¦ä¿å­˜å„è‡ªçš„ç‰¹å¾å›¾æˆ–è€…ç§°Activationï¼Œé‚£ä¹ˆåœ¨addæ“ä½œå‰å ç”¨çš„å†…å­˜å¤§æ¦‚æ˜¯è¾“å…¥Activationçš„ä¸¤å€ï¼Œè€Œå›¾ï¼ˆBï¼‰çš„Plainç»“æ„å ç”¨å†…å­˜å§‹ç»ˆä¸å˜ã€‚

![image-20220710171808769](2101.03697 RepVGG.assets/å•è·¯èŠ‚çœå†…å­˜.png)

- **æ›´åŠ çµæ´»**ï¼šä½œè€…åœ¨è®ºæ–‡ä¸­æåˆ°äº†æ¨¡å‹ä¼˜åŒ–çš„å‰ªæé—®é¢˜ï¼Œå¯¹äºå¤šåˆ†æ”¯çš„æ¨¡å‹ï¼Œç»“æ„é™åˆ¶è¾ƒå¤šå‰ªæå¾ˆéº»çƒ¦ï¼Œè€Œå¯¹äºPlainç»“æ„çš„æ¨¡å‹å°±ç›¸å¯¹çµæ´»å¾ˆå¤šï¼Œå‰ªæä¹Ÿæ›´åŠ æ–¹ä¾¿ã€‚

å…¶å®é™¤æ­¤ä¹‹å¤–ï¼Œåœ¨å¤šåˆ†æ”¯è½¬åŒ–æˆå•è·¯æ¨¡å‹åå¾ˆå¤šç®—å­è¿›è¡Œäº†èåˆï¼ˆæ¯”å¦‚Conv2då’ŒBNèåˆï¼‰ï¼Œä½¿å¾—è®¡ç®—é‡å˜å°äº†ï¼Œè€Œä¸”ç®—å­å‡å°‘åå¯åŠ¨kernelçš„æ¬¡æ•°ä¹Ÿå‡å°‘äº†ï¼ˆæ¯”å¦‚åœ¨GPUä¸­ï¼Œæ¯æ¬¡æ‰§è¡Œä¸€ä¸ªç®—å­å°±è¦å¯åŠ¨ä¸€æ¬¡kernelï¼Œå¯åŠ¨kernelä¹Ÿéœ€è¦æ¶ˆè€—æ—¶é—´ï¼‰ã€‚è€Œä¸”ç°åœ¨çš„ç¡¬ä»¶ä¸€èˆ¬å¯¹`3x3`çš„å·ç§¯æ“ä½œåšäº†å¤§é‡çš„ä¼˜åŒ–ï¼Œè½¬æˆå•è·¯æ¨¡å‹åé‡‡ç”¨çš„éƒ½æ˜¯`3x3`å·ç§¯ï¼Œè¿™æ ·ä¹Ÿèƒ½è¿›ä¸€æ­¥åŠ é€Ÿæ¨ç†ã€‚å¦‚ä¸‹å›¾å¤šåˆ†æ”¯æ¨¡å‹ï¼ˆBï¼‰è½¬æ¢æˆå•è·¯æ¨¡å‹å›¾ï¼ˆCï¼‰ã€‚

![](2101.03697 RepVGG.assets/ç»“æ„é‡å‚æ•°åŒ–.png)

## 2 ç»“æ„é‡å‚æ•°åŒ–

åœ¨ç®€å•äº†è§£RepVGG Blockçš„è®­ç»ƒç»“æ„åï¼Œæ¥ä¸‹æ¥å†æ¥èŠèŠæ€ä¹ˆå°†è®­ç»ƒå¥½çš„RepVGG Blockè½¬æˆæ¨ç†æ—¶çš„æ¨¡å‹ç»“æ„ï¼Œå³`structural re-parameterization technique`è¿‡ç¨‹ã€‚æ ¹æ®è®ºæ–‡ä¸­çš„å›¾4ï¼ˆå·¦ä¾§ï¼‰å¯ä»¥çœ‹åˆ°ï¼Œç»“æ„é‡å‚æ•°åŒ–ä¸»è¦åˆ†ä¸ºä¸¤æ­¥ï¼Œç¬¬ä¸€æ­¥ä¸»è¦æ˜¯å°†Conv2dç®—å­å’ŒBNç®—å­èåˆä»¥åŠå°†åªæœ‰BNçš„åˆ†æ”¯è½¬æ¢æˆä¸€ä¸ªConv2dç®—å­ï¼Œç¬¬äºŒæ­¥å°†æ¯ä¸ªåˆ†æ”¯ä¸Šçš„`3x3`å·ç§¯å±‚èåˆæˆä¸€ä¸ªå·ç§¯å±‚ã€‚å…³äºå‚æ•°å…·ä½“èåˆçš„è¿‡ç¨‹å¯ä»¥çœ‹å›¾ä¸­å³ä¾§çš„éƒ¨åˆ†ï¼Œå¦‚æœä½ èƒ½çœ‹æ‡‚å›¾ä¸­è¦è¡¨è¾¾çš„å«ä¹‰ï¼Œé‚£ä¹ˆokä½ å¯ä»¥è·³è¿‡æœ¬æ–‡åç»­æ‰€æœ‰å†…å®¹å¹²å…¶ä»–äº‹å»äº†ï¼Œå¦‚æœæ²¡çœ‹æ‡‚å¯ä»¥æ¥ç€å¾€åçœ‹ã€‚

![](2101.03697 RepVGG.assets/ç»“æ„é‡å‚æ•°åŒ–1.png)

### 2.1 èåˆConv2då’ŒBN

---

å¦ä¸€ç¯‡åšæ–‡

repVGGä¸­å¤§é‡è¿ç”¨conv+BNå±‚ï¼Œæˆ‘ä»¬çŸ¥é“å°†å±‚åˆå¹¶ï¼Œå‡å°‘å±‚æ•°èƒ½æå‡ç½‘ç»œæ€§èƒ½ï¼Œä¸‹é¢çš„æ¨ç†æ˜¯convå¸¦æœ‰biasçš„è¿‡ç¨‹ï¼š

å·ç§¯å…¬å¼ä¸º
$$
Conv(x) = W(x) + b
$$
è€ŒBNå±‚å…¬å¼ä¸º
$$
BN(x) = \gamma * \frac {x - mean} { \sqrt {var}} + \beta
$$
ç„¶åæˆ‘ä»¬å°†å·ç§¯ç»“æœå¸¦å…¥åˆ°BNå…¬å¼ä¸­
$$
BN(Conv(x)) = \gamma * \frac {W(x)+b-mean} {\sqrt{var}} + \beta
$$
è¿›ä¸€æ­¥åŒ–ç®€ä¸º
$$
BN(Conv(x))
=
\frac{\gamma * W(x)} {\sqrt{var}}
+
\left(\frac{\gamma *(b-mean)}{\sqrt{v a r}}+\beta\right)
$$


è¿™å…¶å®å°±æ˜¯ä¸€ä¸ªå·ç§¯å±‚ï¼Œåªä¸è¿‡æƒé‡è€ƒè™‘äº†BNçš„å‚æ•° æˆ‘ä»¬ä»¤ï¼š
$$
W_{fused}=\frac{\gamma * W}{\sqrt{v a r}} \\
B_{fused}=\frac{\gamma *(b-mean)}{\sqrt{var}}+\beta
$$
æ³¨æ„ï¼Œåœ¨ä½¿ç”¨BNæ—¶å·ç§¯ä¸€èˆ¬æ²¡æœ‰åç½®ï¼Œå°±æ˜¯ä¸Šé¢å…¬å¼ä¸­çš„$b$ï¼ŒåŒ–ç®€ç»“æœå¦‚ä¸‹
$$
W_{fused}=\frac{\gamma * W}{\sqrt{va r}} \\
B_{fused}=\beta - \frac{\gamma *mean}{\sqrt{var}}
$$


æœ€ç»ˆçš„èåˆç»“æœå³ä¸ºï¼š
$$
BN(Conv(x)) = W_{fused}(x) + B_{fused}
$$
ç›¸å…³èåˆä»£ç å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

```python
    #--------------------------------------------#
    #   åˆå¹¶1æ¡åˆ†æ”¯çš„å·ç§¯å’Œbnï¼Œè¿”å›kernelå’Œbias
    #--------------------------------------------#
    def _fuse_bn_tensor(self, branch):
        # rbr_identityåˆ†æ”¯åœ¨å½¢çŠ¶å˜åŒ–æ—¶ä¸ºNone
        if branch is None:
            return 0, 0
        # conv1x1å’Œconv3x3
        if isinstance(branch, nn.Sequential):
            kernel = branch.conv.weight
            running_mean = branch.bn.running_mean
            running_var = branch.bn.running_var
            gamma = branch.bn.weight
            beta = branch.bn.bias
            eps = branch.bn.eps
        else:
            # identityåˆ†æ”¯åªæœ‰ä¸€ä¸ªbn
            assert isinstance(branch, nn.BatchNorm2d)
            # åˆ›å»ºä¸­å¿ƒä¸º1ï¼Œå‘¨å›´ä¸º0çš„3x3å·ç§¯æ ¸ï¼Œè¿™æ ·ç»è¿‡å·ç§¯åå€¼ä¸å˜
            if not hasattr(self, 'id_tensor'):
                input_dim = self.in_channels // self.groups
                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)
                for i in range(self.in_channels):
                    kernel_value[i, i % input_dim, 1, 1] = 1
                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)
            kernel = self.id_tensor
            running_mean = branch.running_mean
            running_var = branch.running_var
            gamma = branch.weight
            beta = branch.bias
            eps = branch.eps
        std = (running_var + eps).sqrt()        # æ ‡å‡†å·®
        t = (gamma / std).reshape(-1, 1, 1, 1)  # Î³
        return kernel * t, beta - running_mean * gamma / std
```



---

å…³äºConv2då’ŒBNçš„èåˆå¯¹äºç½‘ç»œçš„ä¼˜åŒ–è€Œè¨€å·²ç»æ˜¯åŸºæ“äº†ã€‚å› ä¸ºConv2då’ŒBNä¸¤ä¸ªç®—å­éƒ½æ˜¯åšçº¿æ€§è¿ç®—ï¼Œæ‰€ä»¥å¯ä»¥èåˆæˆä¸€ä¸ªç®—å­ã€‚å¦‚æœä¸äº†è§£å·ç§¯å±‚çš„è®¡ç®—è¿‡ç¨‹ä»¥åŠBNçš„è®¡ç®—è¿‡ç¨‹çš„è¯å»ºè®®å…ˆäº†è§£åå†çœ‹è¯¥éƒ¨åˆ†çš„å†…å®¹ã€‚è¿™é‡Œè¿˜éœ€è¦å¼ºè°ƒä¸€ç‚¹ï¼Œèåˆæ˜¯åœ¨ç½‘ç»œè®­ç»ƒå®Œä¹‹ååšçš„ï¼Œæ‰€ä»¥ç°åœ¨è®²çš„é»˜è®¤éƒ½æ˜¯æ¨ç†æ¨¡å¼ï¼Œ**æ³¨æ„BNåœ¨è®­ç»ƒä»¥åŠæ¨ç†æ—¶è®¡ç®—æ–¹å¼æ˜¯ä¸åŒçš„**ã€‚å¯¹äºå·ç§¯å±‚ï¼Œæ¯ä¸ªå·ç§¯æ ¸çš„é€šé“æ•°æ˜¯ä¸è¾“å…¥ç‰¹å¾å›¾çš„é€šé“æ•°ç›¸åŒï¼Œå·ç§¯æ ¸çš„ä¸ªæ•°å†³å®šäº†è¾“å‡ºç‰¹å¾å›¾çš„é€šé“ä¸ªæ•°ã€‚

å¯¹äºBNå±‚ï¼ˆæ¨ç†æ¨¡å¼ï¼‰ï¼Œä¸»è¦åŒ…å«4ä¸ªå‚æ•°ï¼š $\mu$ï¼ˆå‡å€¼ï¼‰ã€$\sigma^2$ï¼ˆæ–¹å·®ï¼‰ã€ $\gamma$ å’Œ $\beta$ï¼Œå…¶ä¸­ $\mu$ å’Œ $\sigma^2$ æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­ç»Ÿè®¡å¾—åˆ°çš„ï¼Œ$\gamma$ å’Œ $\beta $ æ˜¯è®­ç»ƒå­¦ä¹ å¾—åˆ°çš„ã€‚å¯¹äºç‰¹å¾å›¾ç¬¬`i`ä¸ªé€šé“BNçš„è®¡ç®—å…¬å¼å¦‚ä¸‹ï¼Œå…¶ä¸­ $\epsilon$ æ˜¯ä¸€ä¸ªéå¸¸å°çš„å¸¸é‡ï¼Œé˜²æ­¢åˆ†æ¯ä¸ºé›¶ï¼š
$$
y_{i} = 
\frac{x_{i}-\mu_{i}}{\sqrt{\sigma_{i}^{2}+\epsilon}} 
\cdot
\gamma_{i}+\beta_{i}
$$
åœ¨è®ºæ–‡çš„`3.3`ç« èŠ‚ä¸­ï¼Œä½œè€…ç»™å‡ºäº†è½¬æ¢å…¬å¼ï¼ˆå¯¹äºé€šé“`i`ï¼‰ï¼Œå…¶ä¸­ $M$ ä»£è¡¨è¾“å…¥BNå±‚çš„ç‰¹å¾å›¾(Activation)ï¼Œè¿™é‡Œå¿½ç•¥äº† $\epsilon$ ï¼Œå› ä¸ºï¼š
$$
bn(M, \mu, \sigma, \gamma, \beta)_{:, i,:,:}
=
\left(M_{:, i,:,:}-\mu_{i}\right)
\frac{\gamma_{i}}{\sigma_{i}}+\beta_{i}
$$
æ‰€ä»¥è½¬æ¢åæ–°çš„å·ç§¯å±‚æƒé‡è®¡ç®—å…¬å¼ä¸ºï¼ˆå¯¹äºé€šé“`i`ï¼‰ï¼Œ $W^{\prime}$ å’Œ $b^{\prime}$ æ˜¯æ–°çš„æƒé‡å’Œåæ‰§ï¼š
$$
W_{i,:,:,:}^{\prime}
=
\frac{\gamma_{i}}{\sigma_{i}} W_{i,:,:,:}, 
\quad 
b_{i}^{\prime}
=
\beta_{i}-\frac{\mu_{i} \gamma_{i}}{\sigma_{i}}
$$
å¦‚æœçœ‹æ‡‚äº†ï¼Œå¯ä»¥ç›´æ¥è·³è¿‡è¯¥å°ç»“ï¼Œå¦‚æœæ²¡çœ‹æ‡‚å¯ä»¥å†çœ‹çœ‹ä¸‹é¢çš„ä¾‹å­ã€‚

è¿™é‡Œå‡è®¾è¾“å…¥çš„ç‰¹å¾å›¾ï¼ˆInput feature mapï¼‰å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè¾“å…¥é€šé“æ•°ä¸º2ï¼Œç„¶åé‡‡ç”¨ä¸¤ä¸ªå·ç§¯æ ¸ï¼ˆå›¾ä¸­åªç”»äº†ç¬¬ä¸€ä¸ªå·ç§¯æ ¸å¯¹åº”å‚æ•°ï¼‰ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](2101.03697 RepVGG.assets/èåˆConv2då’ŒBNç¤ºä¾‹1.png)

æ¥ç€è®¡ç®—ä¸€ä¸‹è¾“å‡ºç‰¹å¾å›¾ï¼ˆOutput feature  mapï¼‰é€šé“1ä¸Šçš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œå³å½“å·ç§¯æ ¸1åœ¨è¾“å…¥ç‰¹å¾å›¾çº¢è‰²æ¡†åŒºåŸŸå·ç§¯æ—¶å¾—åˆ°çš„å€¼ï¼ˆä¸ºäº†ä¿è¯è¾“å…¥è¾“å‡ºç‰¹å¾å›¾é«˜å®½ä¸å˜ï¼Œæ‰€ä»¥å¯¹Input feature mapè¿›è¡Œäº†Paddingï¼‰ã€‚å…¶ä»–ä½ç½®çš„è®¡ç®—è¿‡ç¨‹ç±»ä¼¼è¿™é‡Œå°±ä¸å»æ¼”ç¤ºäº†ã€‚

![å›¾ç‰‡](2101.03697 RepVGG.assets/èåˆConv2då’ŒBNç¤ºä¾‹2.png)

ç„¶åå†å°†å·ç§¯å±‚è¾“å‡ºçš„ç‰¹å¾å›¾ä½œä¸ºBNå±‚çš„è¾“å…¥ï¼Œè¿™é‡ŒåŒæ ·è®¡ç®—ä¸€ä¸‹è¾“å‡ºç‰¹å¾å›¾ï¼ˆOutput feature mapï¼‰é€šé“1ä¸Šçš„ç¬¬ä¸€ä¸ªå…ƒç´ ï¼ŒæŒ‰ç…§ä¸Šè¿°BNåœ¨æ¨ç†æ—¶çš„è®¡ç®—å…¬å¼å³å¯å¾—åˆ°å¦‚ä¸‹å›¾æ‰€ç¤ºçš„è®¡ç®—ç»“æœã€‚

![](2101.03697 RepVGG.assets/èåˆConv2då’ŒBNç¤ºä¾‹3.png)

æœ€åå¯¹ä¸Šè¿°è®¡ç®—å…¬å¼è¿›è¡Œç®€å•çš„å˜å½¢ï¼Œå¯ä»¥å¾—åˆ°è½¬åŒ–åæ–°å·ç§¯å±‚çš„æƒé‡åªéœ€åœ¨å¯¹åº”é€šé“`i`ä¸Šä¹˜ä»¥ $\frac{\gamma_{i}}{\sqrt{\sigma_{i}^{2}+\epsilon}}$ ç³»æ•°å³å¯ï¼Œå¯¹åº”é€šé“`i`ä¸Šæ–°çš„åæ‰§å°±ç­‰äº $\beta_{i}-\frac{\mu_{i} \gamma_{i}}{\sqrt{\sigma_{i}^{2}+\epsilon}}$å› ä¸ºä¹‹å‰é‡‡ç”¨Conv2d+BNçš„ç»„åˆä¸­Conv2dé»˜è®¤æ˜¯ä¸é‡‡ç”¨åæ‰§çš„æˆ–è€…è¯´åæ‰§ä¸ºé›¶ï¼‰ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](2101.03697 RepVGG.assets/èåˆConv2då’ŒBNç¤ºä¾‹4.png)

### 2.2 Conv2d+BNèåˆå®éªŒ(Pytorch)

ä¸‹é¢æ˜¯å‚è€ƒä½œè€…æä¾›çš„æºç æ”¹çš„ä¸€ä¸ªå°å®éªŒï¼Œé¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ª`module`åŒ…å«äº†å·ç§¯å’ŒBNæ¨¡å—ï¼Œç„¶åæŒ‰ç…§ä¸Šè¿°è½¬æ¢å…¬å¼å°†å·ç§¯å±‚çš„æƒé‡å’ŒBNçš„æƒé‡è¿›è¡Œèåˆè½¬æ¢ï¼Œæ¥ç€è½½å…¥åˆ°æ–°å»ºçš„å·ç§¯æ¨¡å—`fused_conv`ä¸­ï¼Œæœ€åéšæœºåˆ›å»ºä¸€ä¸ªTensorï¼ˆ`f1`ï¼‰å°†å®ƒåˆ†åˆ«è¾“å…¥åˆ°`module`ä»¥åŠ`fused_conv`ä¸­ï¼Œé€šè¿‡å¯¹æ¯”ä¸¤è€…çš„è¾“å‡ºå¯ä»¥å‘ç°å®ƒä»¬çš„ç»“æœæ˜¯ä¸€è‡´çš„ã€‚

```python
from collections import OrderedDict

import numpy as np
import torch
import torch.nn as nn


def main():
    torch.onesom.manual_seed(0)

    f1 = torch.ones(1, 2, 3, 3)

    module = nn.Sequential(OrderedDict(
        conv=nn.Conv2d(in_channels=2, out_channels=2, kernel_size=3, stride=1, padding=1, bias=False),
        bn=nn.BatchNorm2d(num_features=2)
    ))

    module.eval()

    with torch.inference_mode():
        output1 = module(f1)
        print(output1)

    # fuse conv + bn
    kernel = module.conv.weight  # [in_ch, out_ch, k, k]
    running_mean = module.bn.running_mean
    running_var = module.bn.running_var
    gamma = module.bn.weight
    beta = module.bn.bias
    eps = module.bn.eps
    std = (running_var + eps).sqrt()
    t = (gamma / std).reshape(-1, 1, 1, 1)  # [in_ch] -> [in_ch, 1, 1, 1]
    kernel = kernel * t
    bias = beta - running_mean * gamma / std
    fused_conv = nn.Conv2d(in_channels=2, out_channels=2, kernel_size=3, stride=1, padding=1, bias=True)
    fused_conv.load_state_dict(OrderedDict(weight=kernel, bias=bias))

    with torch.inference_mode():
        output2 = fused_conv(f1)
        print(output2)

    np.testing.assert_allclose(output1.numpy(), output2.numpy(), rtol=1e-03, atol=1e-05)
    print("convert module has been tested, and the result looks good!")


if __name__ == '__main__':
    main()
```

ç»ˆç«¯è¾“å‡ºç»“æœï¼š

```python
tensor([[[[ 0.2554, -0.0267,  0.1502],
          [ 0.8394,  1.0100,  0.5443],
          [-0.7252, -0.6889,  0.4716]],

         [[ 0.6937,  0.1421,  0.4734],
          [ 0.0168,  0.5665, -0.2308],
          [-0.2812, -0.2572, -0.1287]]]])
tensor([[[[ 0.2554, -0.0267,  0.1502],
          [ 0.8394,  1.0100,  0.5443],
          [-0.7252, -0.6889,  0.4716]],

         [[ 0.6937,  0.1421,  0.4734],
          [ 0.0168,  0.5665, -0.2308],
          [-0.2812, -0.2572, -0.1287]]]])
convert module has been tested, and the result looks good!
```

### 2.3 å°†1x1å·ç§¯è½¬æ¢æˆ3x3å·ç§¯

è¿™ä¸ªè¿‡ç¨‹æ¯”è¾ƒç®€å•ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä»¥`1x1`å·ç§¯å±‚ä¸­æŸä¸€ä¸ªå·ç§¯æ ¸ä¸ºä¾‹ï¼Œ**åªéœ€åœ¨åŸæ¥æƒé‡å‘¨å›´è¡¥ä¸€åœˆ0**å°±è¡Œäº†ï¼Œè¿™æ ·å°±å˜æˆäº†`3x3`çš„å·ç§¯å±‚ï¼Œæ³¨æ„ä¸ºäº†ä¿è¯è¾“å…¥è¾“å‡ºç‰¹å¾å›¾é«˜å®½ä¸å˜ï¼Œæ­¤æ—¶éœ€è¦å°†paddingè®¾ç½®æˆ1ï¼ˆåŸæ¥å·ç§¯æ ¸å¤§å°ä¸º`1x1`æ—¶paddingä¸º0ï¼‰ã€‚æœ€åæŒ‰ç…§ä¸Šè¿°`2.1`ä¸­è®²çš„å†…å®¹å°†å·ç§¯å±‚å’ŒBNå±‚è¿›è¡Œèåˆå³å¯ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](2101.03697 RepVGG.assets/å°†1x1å·ç§¯è½¬æ¢æˆ3x3å·ç§¯.png)

### 2.4 å°†BNè½¬æ¢æˆ3x3å·ç§¯

å¯¹äºåªæœ‰BNçš„åˆ†æ”¯ç”±äºæ²¡æœ‰å·ç§¯å±‚ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥å…ˆè‡ªå·±æ„å»ºå‡ºä¸€ä¸ªå·ç§¯å±‚æ¥ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæ„å»ºäº†ä¸€ä¸ª`3x3`çš„å·ç§¯å±‚ï¼Œè¯¥å·ç§¯å±‚åªåšäº†æ’ç­‰æ˜ å°„ï¼Œå³è¾“å…¥è¾“å‡ºç‰¹å¾å›¾ä¸å˜ã€‚æ—¢ç„¶æœ‰äº†å·ç§¯å±‚ï¼Œé‚£ä¹ˆåˆå¯ä»¥æŒ‰ç…§ä¸Šè¿°`2.1`ä¸­è®²çš„å†…å®¹å°†å·ç§¯å±‚å’ŒBNå±‚è¿›è¡Œèåˆã€‚

![å›¾ç‰‡](2101.03697 RepVGG.assets/å°†BNè½¬æ¢æˆ3x3å·ç§¯.png)

### 2.5 å¤šåˆ†æ”¯èåˆ

åœ¨ä¸Šé¢çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å·²ç»è®²äº†æ€ä¹ˆæŠŠæ¯ä¸ªåˆ†æ”¯èåˆè½¬æ¢æˆä¸€ä¸ª`3x3`çš„å·ç§¯å±‚ï¼Œæ¥ä¸‹æ¥éœ€è¦è¿›ä¸€æ­¥å°†å¤šåˆ†æ”¯è½¬æ¢æˆä¸€ä¸ªå•è·¯`3x3`å·ç§¯å±‚ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](2101.03697 RepVGG.assets/å¤šåˆ†æ”¯èåˆ1.png)

åˆå¹¶çš„è¿‡ç¨‹å…¶å®ä¹Ÿå¾ˆç®€å•ï¼Œç›´æ¥å°†è¿™ä¸‰ä¸ªå·ç§¯å±‚çš„å‚æ•°ç›¸åŠ å³å¯ï¼Œå…·ä½“æ¨ç†è¿‡ç¨‹å°±ä¸è®²äº†ï¼Œå¦‚æœä¸äº†è§£çš„å¯ä»¥è‡ªå·±åŠ¨æ‰‹ç®—ç®—ã€‚

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](2101.03697 RepVGG.assets/å¤šåˆ†æ”¯èåˆ2.png)

æœ€åæˆ‘ä»¬å†æ¥çœ‹ä¸‹åŸè®ºæ–‡ä¸­çš„å›¾4å°±éå¸¸æ¸…æ™°äº†ã€‚

![](2101.03697 RepVGG.assets/ç»“æ„é‡å‚æ•°åŒ–1.png)

### 2.6 ç»“æ„é‡å‚æ•°åŒ–å®éªŒ(Pytorch)

ä¸‹é¢æ˜¯å‚è€ƒä½œè€…æä¾›çš„æºç æ”¹çš„ä¸€ä¸ªå°å®éªŒï¼Œåœ¨è¯¥å®éªŒä¸­æµ‹è¯•äº† **ç»“æ„é‡å‚æ•°åŒ–** å‰åæ¨ç†é€Ÿåº¦çš„æ¯”è¾ƒï¼Œä»¥åŠæ£€æŸ¥è½¬æ¢å‰åçš„è¾“å‡ºæ˜¯å¦ä¸€è‡´ã€‚

```python
import time
import torch.nn as nn
import numpy as np
import torch


def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):
    result = nn.Sequential()
    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,
                                        kernel_size=kernel_size, stride=stride, padding=padding,
                                        groups=groups, bias=False))
    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))
    return result


class RepVGGBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3,
                 stride=1, padding=1, dilation=1, groups=1, padding_mode='zeros', deploy=False):
        super(RepVGGBlock, self).__init__()
        self.deploy = deploy
        self.groups = groups
        self.in_channels = in_channels
        self.nonlinearity = nn.ReLU()

        if deploy:
            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels,
                                         kernel_size=kernel_size, stride=stride,
                                         padding=padding, dilation=dilation, groups=groups,
                                         bias=True, padding_mode=padding_mode)

        else:
            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) \
                if out_channels == in_channels and stride == 1 else None
            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,
                                     stride=stride, padding=padding, groups=groups)
            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1,
                                   stride=stride, padding=0, groups=groups)

    def forward(self, inputs):
        if hasattr(self, 'rbr_reparam'):
            return self.nonlinearity(self.rbr_reparam(inputs))

        if self.rbr_identity is None:
            id_out = 0
        else:
            id_out = self.rbr_identity(inputs)

        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)

    def get_equivalent_kernel_bias(self):
        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)
        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)
        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)
        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid

    def _pad_1x1_to_3x3_tensor(self, kernel1x1):
        if kernel1x1 is None:
            return 0
        else:
            return torch.nn.functional.pad(kernel1x1, [1, 1, 1, 1])

    def _fuse_bn_tensor(self, branch):
        if branch is None:
            return 0, 0
        if isinstance(branch, nn.Sequential):
            kernel = branch.conv.weight
            running_mean = branch.bn.running_mean
            running_var = branch.bn.running_var
            gamma = branch.bn.weight
            beta = branch.bn.bias
            eps = branch.bn.eps
        else:
            assert isinstance(branch, nn.BatchNorm2d)
            if not hasattr(self, 'id_tensor'):
                input_dim = self.in_channels // self.groups
                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)
                for i in range(self.in_channels):
                    kernel_value[i, i % input_dim, 1, 1] = 1
                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)
            kernel = self.id_tensor
            running_mean = branch.running_mean
            running_var = branch.running_var
            gamma = branch.weight
            beta = branch.bias
            eps = branch.eps
        std = (running_var + eps).sqrt()
        t = (gamma / std).reshape(-1, 1, 1, 1)
        return kernel * t, beta - running_mean * gamma / std

    def switch_to_deploy(self):
        if hasattr(self, 'rbr_reparam'):
            return
        kernel, bias = self.get_equivalent_kernel_bias()
        self.rbr_reparam = nn.Conv2d(in_channels=self.rbr_dense.conv.in_channels,
                                     out_channels=self.rbr_dense.conv.out_channels,
                                     kernel_size=self.rbr_dense.conv.kernel_size, stride=self.rbr_dense.conv.stride,
                                     padding=self.rbr_dense.conv.padding, dilation=self.rbr_dense.conv.dilation,
                                     groups=self.rbr_dense.conv.groups, bias=True)
        self.rbr_reparam.weight.data = kernel
        self.rbr_reparam.bias.data = bias
        for para in self.parameters():
            para.detach_()
        self.__delattr__('rbr_dense')
        self.__delattr__('rbr_1x1')
        if hasattr(self, 'rbr_identity'):
            self.__delattr__('rbr_identity')
        if hasattr(self, 'id_tensor'):
            self.__delattr__('id_tensor')
        self.deploy = True

def main():
    f1 = torch.ones(1, 64, 64, 64)
    block = RepVGGBlock(in_channels=64, out_channels=64)
    block.eval()
    with torch.inference_mode():
        output1 = block(f1)
        start_time = time.time()
        for _ in range(100):
            block(f1)
        print(f"consume time: {time.time() - start_time}")

        # re-parameterization
        block.switch_to_deploy()
        output2 = block(f1)
        start_time = time.time()
        for _ in range(100):
            block(f1)
        print(f"consume time: {time.time() - start_time}")

        np.testing.assert_allclose(output1.numpy(), output2.numpy(), rtol=1e-03, atol=1e-05)
        print("convert module has been tested, and the result looks good!")


if __name__ == '__main__':
    main()
```

ç»ˆç«¯è¾“å‡ºç»“æœå¦‚ä¸‹ï¼š

```python
consume time: 0.6152701377868652
consume time: 0.30626463890075684
convert module has been tested, and the result looks good!
```

é€šè¿‡å¯¹æ¯”èƒ½å¤Ÿå‘ç°ï¼Œ**ç»“æ„é‡å‚æ•°åŒ–**åæ¨ç†é€Ÿåº¦ç¿»å€äº†ï¼Œå¹¶ä¸”è½¬æ¢å‰åçš„è¾“å‡ºä¿æŒä¸€è‡´ã€‚

## 3 æ¨¡å‹é…ç½®

åœ¨è®ºæ–‡ä¸­å¯¹æ¨¡å‹è¿›ä¸€æ­¥ç»†åˆ†æœ‰`RepVGG-A`ã€`RepVGG-B`ä»¥åŠ`RepVGG-Bxgy`ä¸‰ç§é…ç½®ã€‚

![image-20220710173453923](2101.03697 RepVGG.assets/æ¨¡å‹é…ç½®.png)



æ ¹æ®è¡¨2å¯ä»¥çœ‹å‡º`RepVGG-B`æ¯”`RepVGG-A`è¦æ›´æ·±ã€‚å¯ä»¥ç»†çœ‹è¿™ä¸¤ç§é…ç½®åœ¨æ¯ä¸ªstageé‡å¤blockçš„æ¬¡æ•°ã€‚`RepVGG-A`ä¸­çš„base Layers of each stageä¸º`1, 2, 3, 14, 1`è€Œ`RepVGG-B`ä¸­çš„base Layers of each stageä¸º`1, 4, 6, 16, 1`ï¼Œæ›´åŠ è¯¦ç»†çš„æ¨¡å‹é…ç½®å¯ä»¥çœ‹è¡¨3. å…¶ä¸­`a`ä»£è¡¨æ¨¡å‹stage2~4çš„å®½åº¦ç¼©æ”¾å› å­ï¼Œ`b`ä»£è¡¨æ¨¡å‹æœ€åä¸€ä¸ªstageçš„å®½åº¦ç¼©æ”¾å› å­ã€‚

![image-20220710173533638](2101.03697 RepVGG.assets/æ¨¡å‹é…ç½®1.png)

è€Œ`RepVGG-Bxgy`é…ç½®æ˜¯åœ¨`RepVGG-B`çš„åŸºç¡€ä¸ŠåŠ å…¥äº†ç»„å·ç§¯ï¼ˆGroup Convolutionï¼‰ï¼Œå…¶ä¸­`gy`è¡¨ç¤ºç»„å·ç§¯é‡‡ç”¨çš„groupså‚æ•°ä¸º`y`ï¼Œæ³¨æ„å¹¶ä¸æ˜¯æ‰€æœ‰å·ç§¯å±‚éƒ½é‡‡ç”¨ç»„å·ç§¯ï¼Œæ ¹æ®æºç å¯ä»¥çœ‹åˆ°ï¼Œæ˜¯ä»Stage2å¼€å§‹ï¼ˆç´¢å¼•ä»1å¼€å§‹ï¼‰çš„ç¬¬`2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26`çš„å·ç§¯å±‚é‡‡ç”¨ç»„å·ç§¯ã€‚

```python
optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]
```

åˆ°æ­¤ï¼Œæœ‰å…³RepVGGçš„å†…å®¹å°±åŸºæœ¬è®²å®Œäº†ã€‚å¦‚æœè§‰å¾—è¿™ç¯‡æ–‡ç« å¯¹ä½ æœ‰ç”¨ï¼Œè®°å¾—ç‚¹èµã€æ”¶è—å¹¶åˆ†äº«ç»™ä½ çš„å°ä¼™ä¼´ä»¬å“¦ğŸ˜„ã€‚