{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lightning.ai/docs/fabric/stable/\n",
    "\n",
    "https://lightning.ai/docs/fabric/stable/api/fabric_args.html\n",
    "\n",
    "https://lightning.ai/docs/fabric/stable/api/fabric_methods.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lightning_fabric import Fabric\n",
    "from lightning_fabric.loggers import CSVLogger, TensorBoardLogger\n",
    "from torchmetrics.functional import accuracy\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs      = 5\n",
    "batch_size  = 100\n",
    "in_features = 10\n",
    "num_classes = 5\n",
    "data_len    = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=1e-2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sche = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0.001*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.x = torch.randn(data_len, in_features)\n",
    "        self.y = torch.randint(0, num_classes, (data_len,))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datalaoder = DataLoader(dataset=Dataset(), batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_datalaoder   = DataLoader(dataset=Dataset(), batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('fabric_checkpoint')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = Path(\"fabric_checkpoint\")\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loggers = [\n",
    "    CSVLogger(root_dir=output_dir, name = \"\", version=\"\",),\n",
    "    TensorBoardLogger(root_dir=output_dir, name = \"\", version = \"\",),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fabric = Fabric(\n",
    "    accelerator=\"gpu\",  # \"cpu\", \"gpu\", \"tpu\", \"auto\"\n",
    "    # strategy=\"ddp\",   # \"dp\", \"ddp\", \"ddp_spawn\", \"xla\", \"deepspeed\", \"fsdp\", \"auto\"\n",
    "    devices=1,          # \"auto\", -1: run on all GPUs\n",
    "    precision=\"32-true\",# (\"transformer-engine\", \"transformer-engine-float16\", \"16-true\", \"16-mixed\", \"bf16-true\", \"bf16-mixed\", \"32-true\", \"64-true\")\n",
    "    loggers=loggers,\n",
    ")\n",
    "fabric.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fabric.device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local_rank"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> node\n",
    "物理节点，就是一台机器，节点内部可以有多个GPU(一台机器有多卡)。\n",
    "\n",
    "> rank & local_rank\n",
    ">\n",
    "> 用于表示进程的序号，用于进程间通信。每一个进程对应了一个rank。\n",
    ">\n",
    "> rank=0的进程就是master进程。\n",
    ">\n",
    "> local_rank： rank是指在整个分布式任务中进程的序号；local_rank是指在一台机器上(一个node上)进程的相对序号，例如机器一上有0,1,2,3,4,5,6,7，机器二上也有0,1,2,3,4,5,6,7。local_rank在node之间相互独立。\n",
    ">\n",
    "> 单机多卡时，rank就等于local_rank\n",
    "\n",
    "> nnodes\n",
    ">\n",
    "> 物理节点数量\n",
    "\n",
    "> node_rank\n",
    ">\n",
    "> 物理节点的序号\n",
    "\n",
    "> nproc_per_node\n",
    ">\n",
    "> 每个物理节点上面进程的数量。\n",
    "\n",
    "> group\n",
    ">\n",
    "> 进程组。默认只有一个组\n",
    "\n",
    "> world size 全局的并行数\n",
    ">\n",
    "> 全局（一个分布式任务）中，rank的数量。\n",
    ">\n",
    "> 每个node包含16个GPU，且nproc_per_node=8，nnodes=3，机器的node_rank=5，请问world_size是多少？\n",
    ">\n",
    "> 答案：world_size = 3*8 = 24\n",
    "\n",
    "\n",
    "```yaml\n",
    "# 一共有12个rank, nnodes=3, nproc_per_node=4,每个节点都对应一个node_rank\n",
    "\n",
    "machine0:\n",
    "    node_rank: 0\n",
    "        GPU0:\n",
    "            rank: 0\n",
    "            local_rank: 0\n",
    "        GPU1:\n",
    "            rank: 1\n",
    "            local_rank: 1\n",
    "        GPU2:\n",
    "            rank: 2\n",
    "            local_rank: 2\n",
    "        GPU3:\n",
    "            rank: 3\n",
    "            local_rank: 3\n",
    "\n",
    "machine1:\n",
    "    node_rank: 1\n",
    "        GPU0:\n",
    "            rank: 4\n",
    "            local_rank: 0\n",
    "        GPU1:\n",
    "            rank: 5\n",
    "            local_rank: 1\n",
    "        GPU2:\n",
    "            rank: 6\n",
    "            local_rank: 2\n",
    "        GPU3:\n",
    "            rank: 7\n",
    "            local_rank: 3\n",
    "\n",
    "machine2:\n",
    "    node_rank: 2\n",
    "        GPU0:\n",
    "            rank: 8\n",
    "            local_rank: 0\n",
    "        GPU1:\n",
    "            rank: 9\n",
    "            local_rank: 1\n",
    "        GPU2:\n",
    "            rank: 10\n",
    "            local_rank: 2\n",
    "        GPU3:\n",
    "            rank: 11\n",
    "            local_rank: 3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(fabric.local_rank)     # 获取进程 fabric.local_rank==0 代表主进程,相当于 accelerate.is_main_process\n",
    "print(fabric.node_rank)\n",
    "print(fabric.global_rank)\n",
    "print(fabric.is_global_zero) # Whether this rank is rank zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer = fabric.setup(model, optimizer)\n",
    "train_datalaoder = fabric.setup_dataloaders(train_datalaoder)\n",
    "val_datalaoder   = fabric.setup_dataloaders(val_datalaoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clip gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fabric.clip_gradients(module=model, optimizer=optimizer, max_norm=1, norm_type=2)\n",
    "torch.nn.utils.clip_grad.clip_grad_norm_(parameters=model.parameters(), max_norm=1, norm_type=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fabric.clip_gradients(module=model, optimizer=optimizer, clip_val=0.1)\n",
    "# torch.nn.utils.clip_grad.clip_grad_value_(parameters=model.parameters(), clip_value=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/5: 100%|██████████| 100/100 [00:00<00:00, 315.46it/s, train/acc=0.2002]\n",
      "1/5: 100%|██████████| 100/100 [00:00<00:00, 531.92it/s, val/acc=0.1997]\n",
      "2/5: 100%|██████████| 100/100 [00:00<00:00, 315.46it/s, train/acc=0.2037] \n",
      "2/5: 100%|██████████| 100/100 [00:00<00:00, 563.21it/s, val/acc=0.2016]\n",
      "3/5: 100%|██████████| 100/100 [00:00<00:00, 323.63it/s, train/acc=0.1959]\n",
      "3/5: 100%|██████████| 100/100 [00:00<00:00, 568.19it/s, val/acc=0.1980]\n",
      "4/5: 100%|██████████| 100/100 [00:00<00:00, 337.24it/s, train/acc=0.2047]\n",
      "4/5: 100%|██████████| 100/100 [00:00<00:00, 570.18it/s, val/acc=0.2093]\n",
      "5/5: 100%|██████████| 100/100 [00:00<00:00, 334.95it/s, train/acc=0.1936]\n",
      "5/5: 100%|██████████| 100/100 [00:00<00:00, 571.43it/s, val/acc=0.2077]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    # train\n",
    "    model.train()\n",
    "    with tqdm(total = len(train_datalaoder), desc=f\"{epoch}/{epochs}\", disable = fabric.local_rank != 0) as pbar:\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        all_losses = []\n",
    "        for x, y in train_datalaoder:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred: torch.Tensor = model(x) # with automatic autocast https://lightning.ai/docs/fabric/stable/api/fabric_methods.html#autocast\n",
    "            loss: torch.Tensor = loss_fn(y_pred, y)\n",
    "            fabric.backward(loss)   # replace loss.backward()\n",
    "            fabric.clip_gradients(  # 梯度裁剪\n",
    "                module=model,\n",
    "                optimizer=optimizer,\n",
    "                clip_val=None,  # 按照值裁剪\n",
    "                max_norm=1.0,   # 按照梯度裁剪\n",
    "                norm_type=2.0,\n",
    "            )\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_postfix({\"train/loss\": f\"{loss.item():.4f}\"})\n",
    "            pbar.update(1)\n",
    "\n",
    "            # 获取所有数据上的预测值和真实值,用来验证\n",
    "            all_pred, all_tar, all_loss = fabric.all_gather((y_pred, y, loss))\n",
    "            all_predictions.append(all_pred)\n",
    "            all_targets.append(all_tar)\n",
    "            all_losses.append(all_loss)\n",
    "\n",
    "        train_acc = accuracy(\n",
    "            preds=torch.cat(all_predictions, dim=0),\n",
    "            target=torch.cat(all_targets, dim=0),\n",
    "            task=\"multiclass\",\n",
    "            num_classes=num_classes,\n",
    "        )\n",
    "        train_avg_loss = torch.mean(torch.tensor(all_losses))\n",
    "        pbar.set_postfix({\"train/acc\" :f\"{train_acc.item():.4f}\"})\n",
    "\n",
    "    lr_sche.step()\n",
    "\n",
    "    # val\n",
    "    model.eval()\n",
    "    with tqdm(total = len(val_datalaoder), desc=f\"{epoch}/{epochs}\", disable = fabric.local_rank != 0) as pbar:\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        all_losses = []\n",
    "        for x, y in val_datalaoder:\n",
    "            with torch.inference_mode():\n",
    "                y_pred: torch.Tensor = model(x)\n",
    "            loss: torch.Tensor = loss_fn(y_pred, y)\n",
    "\n",
    "            pbar.set_postfix({\"val/loss\": f\"{loss.item():.4f}\"})\n",
    "            pbar.update(1)\n",
    "\n",
    "            # 获取所有数据上的预测值和真实值,用来验证\n",
    "            all_pred, all_tar, all_loss = fabric.all_gather((y_pred, y, loss))\n",
    "            all_predictions.append(all_pred)\n",
    "            all_targets.append(all_tar)\n",
    "            all_losses.append(all_loss)\n",
    "\n",
    "        val_acc = accuracy(\n",
    "            preds=torch.cat(all_predictions, dim=0),\n",
    "            target=torch.cat(all_targets, dim=0),\n",
    "            task=\"multiclass\",\n",
    "            num_classes=num_classes,\n",
    "        )\n",
    "        val_avg_loss = torch.mean(torch.tensor(all_losses))\n",
    "        pbar.set_postfix({\"val/acc\" :f\"{val_acc.item():.4f}\"})\n",
    "\n",
    "    # fabric log\n",
    "    # fabric.log(name=\"val/acc\", value=val_avg_loss.item(), step=epoch)\n",
    "    fabric.log_dict(\n",
    "        metrics={\n",
    "            \"train/acc\": train_acc.item(),\n",
    "            \"train/loss\": train_avg_loss.item(),\n",
    "            \"val/acc\": val_acc.item(),\n",
    "            \"val/loss\": val_avg_loss.item(),\n",
    "        },\n",
    "        step=epoch,\n",
    "    )\n",
    "\n",
    "    # 本地主进程才保存\n",
    "    if fabric.is_global_zero:\n",
    "        # like torch.distributed.barrier, wait for all processes to enter this call.\n",
    "        fabric.barrier()\n",
    "        # save\n",
    "        # You should pass the model and optimizer objects directly into the dictionary so Fabric can unwrap them and automatically retrieve their state-dict.\n",
    "        fabric.save(\n",
    "            path=output_dir / \"fabric.last.pth\",\n",
    "            state={\n",
    "                \"model\": model,\n",
    "                \"optimizer\": optimizer,\n",
    "                \"lr_sche\": lr_sche,\n",
    "            }\n",
    "        )\n",
    "\n",
    "fabric.logger.finalize(\"training finish\")\n",
    "fabric.print(\"training finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fabric.load等同torch.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': OrderedDict([('weight',\n",
       "               tensor([[-0.1348, -0.0855, -0.0954,  0.0417, -0.3190,  0.1403, -0.1463, -0.0071,\n",
       "                        -0.1843, -0.1384],\n",
       "                       [-0.2316, -0.0180,  0.0514,  0.3167, -0.1499,  0.0330,  0.1179,  0.0268,\n",
       "                         0.0168, -0.0062],\n",
       "                       [-0.0115,  0.0963,  0.0759,  0.0937,  0.0938, -0.0601, -0.1356,  0.2082,\n",
       "                        -0.1564, -0.0013],\n",
       "                       [ 0.0964, -0.0995,  0.0425,  0.0931, -0.0945, -0.0394,  0.0584, -0.0102,\n",
       "                         0.0834, -0.1264],\n",
       "                       [-0.0601,  0.0548, -0.0289, -0.0111,  0.0597,  0.0963, -0.0984,  0.2177,\n",
       "                         0.0635,  0.1728]])),\n",
       "              ('bias',\n",
       "               tensor([ 0.1981,  0.0042,  0.1461, -0.2195, -0.0454]))]),\n",
       " 'optimizer': {'state': {0: {'step': tensor(500.),\n",
       "    'exp_avg': tensor([[ 0.0004,  0.0075, -0.0126,  0.0096,  0.0147,  0.0048, -0.0042,  0.0065,\n",
       "             -0.0097,  0.0084],\n",
       "            [-0.0002,  0.0152,  0.0033,  0.0030,  0.0139,  0.0016,  0.0033,  0.0073,\n",
       "              0.0021, -0.0211],\n",
       "            [-0.0106, -0.0052,  0.0170, -0.0098, -0.0122,  0.0127,  0.0018, -0.0082,\n",
       "             -0.0039, -0.0118],\n",
       "            [-0.0026,  0.0039, -0.0019,  0.0008, -0.0110, -0.0140,  0.0003, -0.0041,\n",
       "             -0.0049,  0.0158],\n",
       "            [ 0.0131, -0.0214, -0.0058, -0.0036, -0.0054, -0.0051, -0.0011, -0.0016,\n",
       "              0.0163,  0.0087]]),\n",
       "    'exp_avg_sq': tensor([[0.0008, 0.0006, 0.0008, 0.0008, 0.0009, 0.0008, 0.0007, 0.0007, 0.0008,\n",
       "             0.0009],\n",
       "            [0.0008, 0.0008, 0.0008, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0009,\n",
       "             0.0007],\n",
       "            [0.0009, 0.0010, 0.0009, 0.0008, 0.0008, 0.0008, 0.0007, 0.0006, 0.0007,\n",
       "             0.0008],\n",
       "            [0.0008, 0.0010, 0.0008, 0.0008, 0.0008, 0.0009, 0.0007, 0.0008, 0.0008,\n",
       "             0.0007],\n",
       "            [0.0006, 0.0007, 0.0007, 0.0008, 0.0008, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "             0.0007]])},\n",
       "   1: {'step': tensor(500.),\n",
       "    'exp_avg': tensor([ 0.0011,  0.0034,  0.0118, -0.0007, -0.0155]),\n",
       "    'exp_avg_sq': tensor([0.0007, 0.0008, 0.0009, 0.0007, 0.0008])}},\n",
       "  'param_groups': [{'lr': 0.1,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0.01,\n",
       "    'amsgrad': False,\n",
       "    'foreach': None,\n",
       "    'maximize': False,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'initial_lr': 0.001,\n",
       "    'params': [0, 1]}]},\n",
       " 'lr_sche': {'T_max': 5,\n",
       "  'eta_min': 0.1,\n",
       "  'base_lrs': [0.001],\n",
       "  'last_epoch': 5,\n",
       "  'verbose': False,\n",
       "  '_step_count': 6,\n",
       "  '_get_lr_called_within_step': False,\n",
       "  '_last_lr': [0.1]}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fabric.load(output_dir / \"fabric.last.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': OrderedDict([('weight',\n",
       "               tensor([[-0.1348, -0.0855, -0.0954,  0.0417, -0.3190,  0.1403, -0.1463, -0.0071,\n",
       "                        -0.1843, -0.1384],\n",
       "                       [-0.2316, -0.0180,  0.0514,  0.3167, -0.1499,  0.0330,  0.1179,  0.0268,\n",
       "                         0.0168, -0.0062],\n",
       "                       [-0.0115,  0.0963,  0.0759,  0.0937,  0.0938, -0.0601, -0.1356,  0.2082,\n",
       "                        -0.1564, -0.0013],\n",
       "                       [ 0.0964, -0.0995,  0.0425,  0.0931, -0.0945, -0.0394,  0.0584, -0.0102,\n",
       "                         0.0834, -0.1264],\n",
       "                       [-0.0601,  0.0548, -0.0289, -0.0111,  0.0597,  0.0963, -0.0984,  0.2177,\n",
       "                         0.0635,  0.1728]], device='cuda:0')),\n",
       "              ('bias',\n",
       "               tensor([ 0.1981,  0.0042,  0.1461, -0.2195, -0.0454], device='cuda:0'))]),\n",
       " 'optimizer': {'state': {0: {'step': tensor(500.),\n",
       "    'exp_avg': tensor([[ 0.0004,  0.0075, -0.0126,  0.0096,  0.0147,  0.0048, -0.0042,  0.0065,\n",
       "             -0.0097,  0.0084],\n",
       "            [-0.0002,  0.0152,  0.0033,  0.0030,  0.0139,  0.0016,  0.0033,  0.0073,\n",
       "              0.0021, -0.0211],\n",
       "            [-0.0106, -0.0052,  0.0170, -0.0098, -0.0122,  0.0127,  0.0018, -0.0082,\n",
       "             -0.0039, -0.0118],\n",
       "            [-0.0026,  0.0039, -0.0019,  0.0008, -0.0110, -0.0140,  0.0003, -0.0041,\n",
       "             -0.0049,  0.0158],\n",
       "            [ 0.0131, -0.0214, -0.0058, -0.0036, -0.0054, -0.0051, -0.0011, -0.0016,\n",
       "              0.0163,  0.0087]], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([[0.0008, 0.0006, 0.0008, 0.0008, 0.0009, 0.0008, 0.0007, 0.0007, 0.0008,\n",
       "             0.0009],\n",
       "            [0.0008, 0.0008, 0.0008, 0.0007, 0.0007, 0.0007, 0.0007, 0.0007, 0.0009,\n",
       "             0.0007],\n",
       "            [0.0009, 0.0010, 0.0009, 0.0008, 0.0008, 0.0008, 0.0007, 0.0006, 0.0007,\n",
       "             0.0008],\n",
       "            [0.0008, 0.0010, 0.0008, 0.0008, 0.0008, 0.0009, 0.0007, 0.0008, 0.0008,\n",
       "             0.0007],\n",
       "            [0.0006, 0.0007, 0.0007, 0.0008, 0.0008, 0.0007, 0.0007, 0.0007, 0.0007,\n",
       "             0.0007]], device='cuda:0')},\n",
       "   1: {'step': tensor(500.),\n",
       "    'exp_avg': tensor([ 0.0011,  0.0034,  0.0118, -0.0007, -0.0155], device='cuda:0'),\n",
       "    'exp_avg_sq': tensor([0.0007, 0.0008, 0.0009, 0.0007, 0.0008], device='cuda:0')}},\n",
       "  'param_groups': [{'lr': 0.1,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0.01,\n",
       "    'amsgrad': False,\n",
       "    'foreach': None,\n",
       "    'maximize': False,\n",
       "    'capturable': False,\n",
       "    'differentiable': False,\n",
       "    'fused': None,\n",
       "    'initial_lr': 0.001,\n",
       "    'params': [0, 1]}]},\n",
       " 'lr_sche': {'T_max': 5,\n",
       "  'eta_min': 0.1,\n",
       "  'base_lrs': [0.001],\n",
       "  'last_epoch': 5,\n",
       "  'verbose': False,\n",
       "  '_step_count': 6,\n",
       "  '_get_lr_called_within_step': False,\n",
       "  '_last_lr': [0.1]}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(output_dir / \"fabric.last.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
